{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 4121/4128 [03:49<00:00]        "
     ]
    },
    {
     "ename": "ExplainerError",
     "evalue": "Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 1.388018, while the model output was 1.314670. If this difference is acceptable you can set check_additivity=False to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExplainerError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(model, X_train)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate SHAP values for the test data\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer(X_test)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Summary plot for feature importance\u001b[39;00m\n\u001b[0;32m     26\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values, X_test)\n",
      "File \u001b[1;32mc:\\Users\\e.norouzikandlati\\AppData\\Local\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_tree.py:262\u001b[0m, in \u001b[0;36mTreeExplainer.__call__\u001b[1;34m(self, X, y, interactions, check_additivity)\u001b[0m\n\u001b[0;32m    259\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_feature_names\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interactions:\n\u001b[1;32m--> 262\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshap_values(X, y\u001b[38;5;241m=\u001b[39my, from_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, check_additivity\u001b[38;5;241m=\u001b[39mcheck_additivity, approximate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapproximate)\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    264\u001b[0m         v \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(v, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# put outputs at the end\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\e.norouzikandlati\\AppData\\Local\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_tree.py:510\u001b[0m, in \u001b[0;36mTreeExplainer.shap_values\u001b[1;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[0;32m    508\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_shap_output(phi, flat_output)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_additivity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massert_additivity(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(X))\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# This statements handles the case of multiple outputs\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m# e.g. a multi-class classification problem, multi-target regression problem\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# in this case the output shape corresponds to [num_samples, num_features, num_outputs]\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\e.norouzikandlati\\AppData\\Local\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_tree.py:680\u001b[0m, in \u001b[0;36mTreeExplainer.assert_additivity\u001b[1;34m(self, phi, model_output)\u001b[0m\n\u001b[0;32m    678\u001b[0m         check_sum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value[i] \u001b[38;5;241m+\u001b[39m phi[i]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), model_output[:,i])\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m     check_sum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m+\u001b[39m phi\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), model_output)\n",
      "File \u001b[1;32mc:\\Users\\e.norouzikandlati\\AppData\\Local\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_tree.py:674\u001b[0m, in \u001b[0;36mTreeExplainer.assert_additivity.<locals>.check_sum\u001b[1;34m(sum_val, model_output)\u001b[0m\n\u001b[0;32m    670\u001b[0m     err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Consider retrying with the feature_perturbation=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterventional\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m option.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This check failed because for one of the samples the sum of the SHAP values\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    672\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msum_val[ind]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, while the model output was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_output[ind]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If this\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    673\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m difference is acceptable you can set check_additivity=False to disable this check.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 674\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ExplainerError(err_msg)\n",
      "\u001b[1;31mExplainerError\u001b[0m: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 1.388018, while the model output was 1.314670. If this difference is acceptable you can set check_additivity=False to disable this check."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing  # Import an example dataset\n",
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load California housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize the SHAP explainer\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "\n",
    "# Calculate SHAP values for the test data\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Summary plot for feature importance\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
